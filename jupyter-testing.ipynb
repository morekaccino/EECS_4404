{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def activation(s):\n",
    "    return 0 if s <= 0 else s\n",
    "\n",
    "def derivativeActivation(s):\n",
    "    # return 0 if s <= 0 else 1\n",
    "    return (1 - tanh(s) ** 2)\n",
    "    # return (1 - (s) ** 2)\n",
    "\n",
    "def derivativeActivationW(s):\n",
    "    # return 0 if s <= 0 else 1\n",
    "    # return (1 - tanh(s) ** 2)\n",
    "    return (1 - (s ** 2))\n",
    "\n",
    "\n",
    "def outputf(s):\n",
    "    return (1) / ((1) + np.exp(-s))\n",
    "\n",
    "def derivativeOutput(s):\n",
    "    return (outputf(s)) * (1 - outputf(s))\n",
    "\n",
    "def errorf(x_L, y):\n",
    "    if y == 1:\n",
    "        return np.log(x_L)\n",
    "    else:\n",
    "        return -np.log(1 - x_L)\n",
    "    \n",
    "def tanh(s):\n",
    "    return np.tanh(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "X = [1, 2]\n",
    "W = [\n",
    "    [[0.1,0.2],\n",
    "     [0.3,0.4]],\n",
    "    [[0.2],\n",
    "     [1],\n",
    "     [-3]],\n",
    "    [[1],\n",
    "     [2]]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def forwardPropagation(x, weights):\n",
    "    Xl = np.array(x)\n",
    "    W = np.array(weights)\n",
    "    S = []\n",
    "    X = [x]\n",
    "    for index,l in enumerate(W):\n",
    "        wl = np.array(l)\n",
    "        sl = np.transpose(wl).dot(Xl)\n",
    "        Xl_before_activation = sl\n",
    "        if index != len(W) - 1:\n",
    "            activation_function = np.vectorize(tanh)\n",
    "            Xl = activation_function(Xl_before_activation)\n",
    "            Xl = np.insert(Xl, 0, 1, axis=0)\n",
    "        else:\n",
    "            output_function = np.vectorize(tanh)\n",
    "            Xl = output_function(Xl_before_activation)\n",
    "        X.append(Xl)\n",
    "        S.append(sl)\n",
    "    np.delete\n",
    "    return np.array(X),np.array(S)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.7 1. ]\n[-1.48041469]\n[-0.80309131]\n\n [array([0.7, 1. ]) array([-1.48041469]) array([-0.80309131])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x,s = forwardPropagation(X,W)\n",
    "for i in s:\n",
    "    print(i)\n",
    "print('\\n',s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def backPropagation(X, y_n, s, weights):\n",
    "    weights_copy = deepcopy(weights)\n",
    "    g = [None] * len(X)\n",
    "    X = np.array(X)\n",
    "    for layer, Xl in enumerate(reversed(X)):\n",
    "        layer = len(X) - layer - 1\n",
    "        if layer == len(X) - 1:\n",
    "            delta = 2 * (Xl[0] - y_n) * derivativeActivation(s[-1][0])\n",
    "            g[layer] = np.array([delta])\n",
    "        elif layer > 0:\n",
    "            derivatives = np.zeros([len(Xl) - 1,len(Xl) - 1])\n",
    "            for i in range(len(Xl) - 1):\n",
    "                derivatives[i][i] = derivativeActivationW(Xl[i + 1])\n",
    "            \n",
    "            Wl = weights_copy[layer]\n",
    "            Wl_t = np.array(Wl)\n",
    "            g[layer] = ((Wl_t).dot((g[layer + 1]).T)[1:]).T.dot(derivatives)\n",
    "            \n",
    "            \n",
    "            print('Wl',Wl)\n",
    "            print('gl', g[layer + 1])\n",
    "            print('der', derivatives)\n",
    "            print('------------------------------')            \n",
    "            \n",
    "    g = g[1:]\n",
    "    \n",
    "    \n",
    "    updatedW = weights_copy\n",
    "    for layer, Xl in enumerate(X[:-1]):\n",
    "        # Xl = np.array(Xl).reshape(len(Xl),)\n",
    "        print(Xl)\n",
    "        print(g[layer])\n",
    "        print('------------------------------')\n",
    "        # updatedW[layer] = Xl.T.dot(g[layer])\n",
    "        updatedW[layer] = np.dot(np.array([Xl]).T, np.array([g[layer]]))\n",
    "    \n",
    "    return (updatedW)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wl [[1], [2]]\ngl [-1.85486437]\nder [[0.18721543]]\n------------------------------\nWl [[0.2], [1], [-3]]\ngl [-0.69451848]\nder [[0.63473959 0.        ]\n [0.         0.41997434]]\n------------------------------\n[1, 2]\n[-0.44083838  0.87503983]\n------------------------------\n[1.         0.60436778 0.76159416]\n[-0.69451848]\n------------------------------\n[ 1.         -0.90154565]\n[-1.85486437]\n------------------------------\n[[-0.44083838  0.87503983]\n [-0.88167675  1.75007965]]\n[[-0.69451848]\n [-0.41974459]\n [-0.52894122]]\n[[-1.85486437]\n [ 1.67224491]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "g = backPropagation(x, 1, s, W)\n",
    "for i in g:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "data": {
      "text/plain": "[[[0.1, 0.2], [0.3, 0.4]], [[0.2], [1], [-3]], [[1], [2]]]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 369
    }
   ],
   "source": [
    "W"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "def updateWeights(weights, g, alpha):\n",
    "    nW = deepcopy(weights)\n",
    "    for i in range(len(nW)):\n",
    "        for j in range(len(nW[i])):\n",
    "            nW[i][j] = nW[i][j] - (alpha * g[i][j]) \n",
    "    return nW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[array([ 0.54083838, -0.67503983]), array([ 1.18167675, -1.35007965])]\n[array([0.89451848]), array([1.41974459]), array([-2.47105878])]\n[array([2.85486437]), array([0.32775509])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "nW = updateWeights(W, g, 1)\n",
    "for i in nW:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "outputs": [],
   "source": [
    "# def fit_NeuralNetwork(X_train, y_train, alpha, hidden_layer_sizes, epochs):\n",
    "#     init_val_division = 1 / 0.1\n",
    "#     layer_size = [len(X_train[-1])] + hidden_layer_sizes + [1]\n",
    "#     dims = []\n",
    "#     for layer, d in enumerate(layer_size):\n",
    "#         try:\n",
    "#             temp = (d + 1, layer_size[layer + 1])\n",
    "#             dims.append(np.array([np.ones(temp) / init_val_division]))\n",
    "#         except Exception as e:\n",
    "#             pass\n",
    "#     W = np.array([dims]).T\n",
    "#     return W\n",
    "def fit_NeuralNetwork(X_train, y_train, alpha, hidden_layer_sizes, epochs):\n",
    "    layer_units = ([len(X_train[-1])] + hidden_layer_sizes + [len(y_train[-1])])\n",
    "    W = [np.empty((n_fan_in_ + 1, n_fan_out_)) for n_fan_in_,\n",
    "                                                        n_fan_out_ in zip(layer_units[:-1],\n",
    "                                                                       layer_units[1:])]\n",
    "    X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "    for _ in range(epochs):\n",
    "        for N, x_n in enumerate(X_train):\n",
    "            X_n ,S_n = forwardPropagation(x_n, W)\n",
    "            g_n = backPropagation(X_n, y_train[N], S_n, W)\n",
    "            W = updateWeights(W, g_n, alpha)\n",
    "    return W"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wl [[1.        ]\n [0.90154565]]\ngl [[-0.00744834]]\nder [[0.]]\n------------------------------\nWl [[ 4.]\n [ 8.]\n [12.]]\ngl [[-0.]]\nder [[0.04753486 0.        ]\n [0.         0.00063339]]\n------------------------------\n[1 2]\n[[0. 0.]]\n------------------------------\n[1.         0.97594321 0.99968325]\n[[-0.]]\n------------------------------\n[1. 1.]\n[[-0.00744834]]\n------------------------------\n[array([[0.44083838, 0.87503983],\n       [0.88167675, 1.75007965]]), array([[ 4.],\n       [ 8.],\n       [12.]]), array([[1.00744834],\n       [0.90899399]])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "w = fit_NeuralNetwork([[2]],[[1],[-1]],1,[2,1],1)\n",
    "print(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}