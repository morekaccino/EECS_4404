{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def activation(s):\n",
    "    return 0 if s <= 0 else s\n",
    "\n",
    "def derivativeActivation(s):\n",
    "    # return 0 if s <= 0 else 1\n",
    "    return (1 - tanh(s) ** 2)\n",
    "    # return (1 - (s) ** 2)\n",
    "\n",
    "def derivativeActivationW(s):\n",
    "    # return 0 if s <= 0 else 1\n",
    "    # return (1 - tanh(s) ** 2)\n",
    "    return (1 - (s ** 2))\n",
    "\n",
    "\n",
    "def outputf(s):\n",
    "    return (1) / ((1) + np.exp(-s))\n",
    "\n",
    "def derivativeOutput(s):\n",
    "    return (outputf(s)) * (1 - outputf(s))\n",
    "\n",
    "def errorf(x_L, y):\n",
    "    if y == 1:\n",
    "        return np.log(x_L)\n",
    "    else:\n",
    "        return -np.log(1 - x_L)\n",
    "    \n",
    "def errorPerSample(X, yn):\n",
    "    return errorf(X[-1][-1], yn)\n",
    "    \n",
    "def tanh(s):\n",
    "    return np.tanh(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "X = [1, 2]\n",
    "W = [\n",
    "    [[0.1,0.2],\n",
    "     [0.3,0.4]],\n",
    "    [[0.2],\n",
    "     [1],\n",
    "     [-3]],\n",
    "    [[1],\n",
    "     [2]]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def forwardPropagation(x, weights):\n",
    "    Xl = np.array(x)\n",
    "    W = np.array(weights)\n",
    "    S = []\n",
    "    X = [x]\n",
    "    for index,l in enumerate(W):\n",
    "        wl = np.array(l)\n",
    "        sl = np.transpose(wl).dot(Xl)\n",
    "        Xl_before_activation = sl\n",
    "        if index != len(W) - 1:\n",
    "            activation_function = np.vectorize(tanh)\n",
    "            Xl = activation_function(Xl_before_activation)\n",
    "            Xl = np.insert(Xl, 0, 1, axis=0)\n",
    "        else:\n",
    "            output_function = np.vectorize(tanh)\n",
    "            Xl = output_function(Xl_before_activation)\n",
    "        X.append(Xl)\n",
    "        S.append(sl)\n",
    "    return np.array(X),np.array(S)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1, 2]\n[1.         0.60436778 0.76159416]\n[ 1.         -0.90154565]\n[-0.66576144]\n\n [array([0.7, 1. ]) array([-1.48041469]) array([-0.80309131])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x,s = forwardPropagation(X,W)\n",
    "for i in x:\n",
    "    print(i)\n",
    "print('\\n',s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def backPropagation(X, y_n, s, weights):\n",
    "    # weights_copy = deepcopy(weights)\n",
    "    g = [None] * len(X)\n",
    "    X = np.array(X)\n",
    "    for layer, Xl in enumerate(reversed(X)):\n",
    "        layer = len(X) - layer - 1\n",
    "        if layer == len(X) - 1:\n",
    "            delta = 2 * (Xl[0] - y_n) * derivativeActivation(s[-1][0])\n",
    "            g[layer] = np.array([delta])\n",
    "        elif layer > 0:\n",
    "            derivatives = np.zeros([len(Xl) - 1,len(Xl) - 1])\n",
    "            for i in range(len(Xl) - 1):\n",
    "                derivatives[i][i] = derivativeActivationW(Xl[i + 1])\n",
    "            \n",
    "            Wl = weights[layer]\n",
    "            Wl_t = np.array(Wl)\n",
    "            g[layer] = ((Wl_t).dot((g[layer + 1]).T)[1:]).T.dot(derivatives)\n",
    "            \n",
    "            \n",
    "            # print('Wl',Wl)\n",
    "            # print('gl', g[layer + 1])\n",
    "            # print('der', derivatives)\n",
    "            # print('------------------------------')            \n",
    "            \n",
    "    g = g[1:]\n",
    "    \n",
    "    \n",
    "    updatedW = weights\n",
    "    for layer, Xl in enumerate(X[:-1]):\n",
    "        # print(Xl)\n",
    "        # print(g[layer])\n",
    "        # print('------------------------------')\n",
    "        updatedW[layer] = np.dot(np.array([Xl]).T, np.array([g[layer]]))\n",
    "    \n",
    "    return (updatedW)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[-0.44083838  0.87503983]\n [-0.88167675  1.75007965]]\n[[-0.69451848]\n [-0.41974459]\n [-0.52894122]]\n[[-1.85486437]\n [ 1.67224491]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "g = backPropagation(x, 1, s, W)\n",
    "for i in g:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[-0.44083838,  0.87503983],\n        [-0.88167675,  1.75007965]]), array([[-0.69451848],\n        [-0.41974459],\n        [-0.52894122]]), array([[-1.85486437],\n        [ 1.67224491]])]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "W"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def updateWeights(weights, g, alpha):\n",
    "    nW = deepcopy(weights)\n",
    "    for i in range(len(nW)):\n",
    "        for j in range(len(nW[i])):\n",
    "            nW[i][j] = nW[i][j] - (alpha * g[i][j]) \n",
    "    return nW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0. 0.]\n [0. 0.]]\n[[0.]\n [0.]\n [0.]]\n[[0.]\n [0.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "nW = updateWeights(W, g, 1)\n",
    "for i in nW:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def fit_NeuralNetwork(X_train, y_train, alpha, hidden_layer_sizes, epochs):\n",
    "    layer_units = ([len(X_train[-1])] + hidden_layer_sizes + [len(y_train[-1])])\n",
    "    weight = [np.zeros((n_fan_in_ + 1, n_fan_out_)) * 0 + 0.1 for n_fan_in_,\n",
    "                                                        n_fan_out_ in zip(layer_units[:-1],\n",
    "                                                                       layer_units[1:])]\n",
    "    X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "    error_list = []\n",
    "    for _ in range(epochs):\n",
    "        error_over_epoch = 0\n",
    "        for N, x_n in enumerate(X_train):\n",
    "            X_n ,S_n = forwardPropagation(x_n, W)\n",
    "            g_n = backPropagation(X_n, y_train[N], S_n, W)\n",
    "            weight = updateWeights(weight, g_n, alpha)\n",
    "            error_over_epoch += errorPerSample(X_n, y_train[N])\n",
    "        error_list.append(error_over_epoch / len(X_train))\n",
    "    return weight, error_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fa76d67b62f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_NeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-b2a5db4f1893>\u001b[0m in \u001b[0;36mfit_NeuralNetwork\u001b[1;34m(X_train, y_train, alpha, hidden_layer_sizes, epochs)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0merror_over_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mX_n\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mS_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mg_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdateWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-6f579d08ec62>\u001b[0m in \u001b[0;36mforwardPropagation\u001b[1;34m(x, weights)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mwl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mXl_before_activation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,1,2) and (2,1,1) not aligned: 2 (dim 2) != 1 (dim 1)"
     ],
     "ename": "ValueError",
     "evalue": "shapes (1,1,2) and (2,1,1) not aligned: 2 (dim 2) != 1 (dim 1)",
     "output_type": "error"
    }
   ],
   "source": [
    "w, err = fit_NeuralNetwork([[3],[2],[-2]],[[1],[1],[-1]],1,[2,1],100)\n",
    "print(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def pred(x_n, weights):\n",
    "    x_n = np.insert(x_n, 0, 1, axis=0)\n",
    "    x,s = forwardPropagation(x_n, weights)\n",
    "    return 1 if  x[-1][-1] >= 0.5 else -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "pred([1], w)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def confMatrix(X_train, y_train, w):\n",
    "    # Add implementation here\n",
    "    y_pred = []\n",
    "    for x_n in X_train:\n",
    "        y_pred.append(pred(x_n, w))\n",
    "\n",
    "    # the confusion maxtrix that we will return\n",
    "    # matrix = [[0, 0], [0, 0]]\n",
    "    matrix = np.zeros((2, 2), np.int8)\n",
    "\n",
    "    # Populating our matrix using the prediction data\n",
    "    for index, y in enumerate(y_train):\n",
    "        if y == -1 and y_pred[index] == -1:\n",
    "            matrix[0][0] += 1\n",
    "        elif y == -1 and y_pred[index] == 1:\n",
    "            matrix[0][1] += 1\n",
    "        elif y == 1 and y_pred[index] == -1:\n",
    "            matrix[1][0] += 1\n",
    "        else:\n",
    "            matrix[1][1] += 1\n",
    "\n",
    "    # returning the result\n",
    "    return matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X_train, y_train = load_iris(return_X_y=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1a66f8d49af8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int32' has no len()"
     ],
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int32' has no len()",
     "output_type": "error"
    }
   ],
   "source": [
    "len(y_train[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}