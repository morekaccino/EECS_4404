{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def activation(s):\n",
    "    return 0 if s <= 0 else s\n",
    "\n",
    "def derivativeActivation(s):\n",
    "    # return 0 if s <= 0 else 1\n",
    "    return (1 - tanh(s) ** 2)\n",
    "    # return (1 - (s) ** 2)\n",
    "\n",
    "def derivativeActivationW(s):\n",
    "    # return 0 if s <= 0 else 1\n",
    "    # return (1 - tanh(s) ** 2)\n",
    "    return (1 - (s ** 2))\n",
    "\n",
    "\n",
    "def outputf(s):\n",
    "    return (1) / ((1) + np.exp(-s))\n",
    "\n",
    "def derivativeOutput(s):\n",
    "    return (outputf(s)) * (1 - outputf(s))\n",
    "\n",
    "def errorf(x_L, y):\n",
    "    if y == 1:\n",
    "        return np.log(x_L)\n",
    "    else:\n",
    "        return -np.log(1 - x_L)\n",
    "    \n",
    "def tanh(s):\n",
    "    return np.tanh(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "X = [1, 2]\n",
    "W = [\n",
    "    [[0.1,0.2],\n",
    "     [0.3,0.4]],\n",
    "    [[0.2],\n",
    "     [1],\n",
    "     [-3]],\n",
    "    [[1],\n",
    "     [2]]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def forwardPropagation(x, weights):\n",
    "    Xl = np.array(x)\n",
    "    W = np.array(weights)\n",
    "    S = []\n",
    "    X = [x]\n",
    "    for index,l in enumerate(W):\n",
    "        wl = np.array(l)\n",
    "        sl = np.transpose(wl).dot(Xl)\n",
    "        Xl_before_activation = sl\n",
    "        if index != len(W) - 1:\n",
    "            activation_function = np.vectorize(tanh)\n",
    "            Xl = activation_function(Xl_before_activation)\n",
    "            Xl = np.insert(Xl, 0, 1, axis=0)\n",
    "        else:\n",
    "            output_function = np.vectorize(tanh)\n",
    "            Xl = output_function(Xl_before_activation)\n",
    "        X.append(Xl)\n",
    "        S.append(sl)\n",
    "    np.delete\n",
    "    return np.array(X),np.array(S)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.7 1. ]\n[-1.48041469]\n[-0.80309131]\n\n [array([0.7, 1. ]) array([-1.48041469]) array([-0.80309131])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x,s = forwardPropagation(X,W)\n",
    "for i in s:\n",
    "    print(i)\n",
    "print('\\n',s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "def backPropagation(X, y_n, s, weights):\n",
    "    weights_copy = weights\n",
    "    g = [None] * len(X)\n",
    "    X = np.array(X)\n",
    "    for layer, Xl in enumerate(reversed(X)):\n",
    "        layer = len(X) - layer - 1\n",
    "        if layer == len(X) - 1:\n",
    "            delta = 2 * (Xl[0] - y_n) * derivativeActivation(s[-1][0])\n",
    "            g[layer] = np.array([delta])\n",
    "        elif layer > 0:\n",
    "            derivatives = np.zeros([len(Xl) - 1,len(Xl) - 1])\n",
    "            for i in range(len(Xl) - 1):\n",
    "                derivatives[i][i] = derivativeActivationW(Xl[i + 1])\n",
    "            \n",
    "            Wl = weights_copy[layer]\n",
    "            Wl_t = np.array(Wl)\n",
    "            g[layer] = ((Wl_t).dot((g[layer + 1]).T)[1:]).T.dot(derivatives)\n",
    "            \n",
    "            \n",
    "            print('Wl',Wl)\n",
    "            print('gl', g[layer + 1])\n",
    "            print('der', derivatives)\n",
    "            print('------------------------------')            \n",
    "            \n",
    "    g = g[1:]\n",
    "    \n",
    "    \n",
    "    updatedW = weights_copy\n",
    "    for layer, Xl in enumerate(X[:-1]):\n",
    "        # Xl = np.array(Xl).reshape(len(Xl),)\n",
    "        print(Xl)\n",
    "        print(g[layer])\n",
    "        print('------------------------------')\n",
    "        # updatedW[layer] = Xl.T.dot(g[layer])\n",
    "        updatedW[layer] = np.dot(np.array([Xl]).T, np.array([g[layer]]))\n",
    "    \n",
    "    return (updatedW)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wl [[1], [2]]\ngl [-1.85486437]\nder [[0.18721543]]\n------------------------------\nWl [[0.2], [1], [-3]]\ngl [-0.69451848]\nder [[0.63473959 0.        ]\n [0.         0.41997434]]\n------------------------------\n[1, 2]\n[-0.44083838  0.87503983]\n------------------------------\n[1.         0.60436778 0.76159416]\n[-0.69451848]\n------------------------------\n[ 1.         -0.90154565]\n[-1.85486437]\n------------------------------\n[[-0.44083838  0.87503983]\n [-0.88167675  1.75007965]]\n[[-0.69451848]\n [-0.41974459]\n [-0.52894122]]\n[[-1.85486437]\n [ 1.67224491]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "g = backPropagation(x, 1, s, W)\n",
    "for i in g:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[-0.44083838,  0.87503983],\n        [-0.88167675,  1.75007965]]), array([[-0.69451848],\n        [-0.41974459],\n        [-0.52894122]]), array([[-1.85486437],\n        [ 1.67224491]])]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 358
    }
   ],
   "source": [
    "W"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}